server.port = 8080

langchain4j.open-ai.chat-model.base-url=http://langchain4j.dev/demo/openai/v1
langchain4j.open-ai.chat-model.api-key=demo
langchain4j.open-ai.chat-model.model-name=gpt-4o-mini

#\u5E94\u7528\u7A0B\u5E8F\u53D1\u9001\u7ED9\u5927\u6A21\u578B\u7684\u8BF7\u6C42\u65E5\u5FD7\u548C\u54CD\u5E94\u65E5\u5FD7
langchain4j.open-ai.chat-model.log-request=true
langchain4j.open-ai.chat-model.log-response=true
#\u5C06\u7CFB\u7EDF\u65E5\u5FD7\u8BBE\u7F6E\u4E3Adebug\u7EA7\u522B
logging.level.root=info

deepseek.base-url=https://api.deepseek.com
deepseek.api-key=sk-5af0b392f7b44db6aa4bfe639ac29f01
deepseek.model-name=deepseek-chat

#langchain4j.open-ai.chat-model.base-url=https://api.deepseek.com
#langchain4j.open-ai.chat-model.api-key=sk-5af0b392f7b44db6aa4bfe639ac29f01
#langchain4j.open-ai.chat-model.model-name=deepseek-chat

langchain4j.ollama.chat-model.base-url=http://localhost:11434
#langchain4j.ollama.chat-model.model-name=deepseek-r1:latest
langchain4j.ollama.chat-model.model-name=qwen3:4b
langchain4j.ollama.chat-model.temperature=0.8
langchain4j.ollama.chat-model.timeout=PT60S

langchain4j.community.dashscope.chat-model.api-key=http://localhost:11434
langchain4j.community.dashscope.chat-model.model-name=qwen3:4b